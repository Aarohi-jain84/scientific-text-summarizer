{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+e2dai0vFhTjd6A1ukHtx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aarohi-jain84/scientific-text-summarizer/blob/main/Scientific_Text_Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cgLQaQD0M9Z",
        "outputId": "fee1ec32-dd7f-4c50-98f9-258697a47798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.24.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.11/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "# üì¶ Install necessary libraries for NLP and summarization\n",
        "!pip install nltk gensim transformers scikit-learn sumy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö Import required libraries and download NLTK resources\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Explicitly request punkt_tab\n",
        "nltk.download('tokenizers/punkt')  # Tries full path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlxcF2771PaY",
        "outputId": "54c95f41-3965-4c60-af0e-f8731e9f8e67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Error loading tokenizers/punkt: Package 'tokenizers/punkt'\n",
            "[nltk_data]     not found in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üßº Preprocess: Tokenize text, remove stopwords, and filter meaningful words\n",
        "sample_text = \"\"\"\n",
        "Graph neural networks (GNNs) have emerged as a powerful framework for representation learning on graphs.\n",
        "They achieve state-of-the-art results on tasks such as node classification, link prediction, and graph classification.\n",
        "In this work, we investigate how architectural choices influence the performance of GNNs and propose new variants\n",
        "with improved expressiveness and efficiency.\n",
        "\"\"\"\n",
        "\n",
        "# Convert to lowercase and tokenize\n",
        "words = word_tokenize(sample_text.lower())\n",
        "\n",
        "# Remove stopwords and non-alphanumeric tokens\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "print(\"Filtered Words:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8cXpTQW1diE",
        "outputId": "d6f8ffc3-f34d-434b-d662-a03d11776a29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Words: ['graph', 'neural', 'networks', 'gnns', 'emerged', 'powerful', 'framework', 'representation', 'learning', 'graphs', 'achieve', 'results', 'tasks', 'node', 'classification', 'link', 'prediction', 'graph', 'classification', 'work', 'investigate', 'architectural', 'choices', 'influence', 'performance', 'gnns', 'propose', 'new', 'variants', 'improved', 'expressiveness', 'efficiency']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìù Summarization using Sumy's LSA method\n",
        "\n",
        "# Convert the text into a parser-friendly format\n",
        "parser = PlaintextParser.from_string(sample_text, Tokenizer(\"english\"))\n",
        "\n",
        "# Initialize the LSA summarizer\n",
        "lsa_summarizer = LsaSummarizer()\n",
        "\n",
        "# Generate the summary (limit to 2 sentences)\n",
        "summary = lsa_summarizer(parser.document, 2)\n",
        "\n",
        "# Display the summary\n",
        "print(\"üîç LSA Summary:\")\n",
        "for sentence in summary:\n",
        "    print(\"-\", sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTaPT-SJ1xp8",
        "outputId": "226d5ddb-722b-489c-a662-49227a8b42a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç LSA Summary:\n",
            "- Graph neural networks (GNNs) have emerged as a powerful framework for representation learning on graphs.\n",
            "- In this work, we investigate how architectural choices influence the performance of GNNs and propose new variants with improved expressiveness and efficiency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Summarization using TF-IDF sentence scoring\n",
        "\n",
        "# Step 1: Split the text into sentences\n",
        "sentences = sent_tokenize(sample_text)\n",
        "\n",
        "# Step 2: Use TF-IDF Vectorizer to compute sentence-level TF-IDF scores\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# Step 3: Compute sentence importance as the sum of TF-IDF scores\n",
        "sentence_scores = tfidf_matrix.sum(axis=1).flatten().tolist()[0]\n",
        "\n",
        "# Step 4: Pair scores with sentences and sort them\n",
        "scored_sentences = list(zip(sentence_scores, sentences))\n",
        "scored_sentences.sort(reverse=True)\n",
        "\n",
        "# Step 5: Extract top 2 sentences\n",
        "top_sentences = [sent for score, sent in scored_sentences[:2]]\n",
        "\n",
        "# Step 6: Display the summary\n",
        "print(\"üß© TF-IDF Summary:\")\n",
        "for sent in top_sentences:\n",
        "    print(\"-\", sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_IfmKdA4qr-",
        "outputId": "aeae27d2-4784-4364-c3a8-9454650ab8cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß© TF-IDF Summary:\n",
            "- In this work, we investigate how architectural choices influence the performance of GNNs and propose new variants\n",
            "with improved expressiveness and efficiency.\n",
            "- \n",
            "Graph neural networks (GNNs) have emerged as a powerful framework for representation learning on graphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Summarization using LSA (Latent Semantic Analysis) from Sumy\n",
        "\n",
        "# Step 1: Initialize Sumy parser\n",
        "parser = PlaintextParser.from_string(sample_text, Tokenizer(\"english\"))\n",
        "\n",
        "# Step 2: Apply LSA Summarizer\n",
        "lsa_summarizer = LsaSummarizer()\n",
        "lsa_summary = lsa_summarizer(parser.document, 2)  # Number of summary sentences\n",
        "\n",
        "# Step 3: Display summary\n",
        "print(\"\\nüîç LSA Summary:\")\n",
        "for sentence in lsa_summary:\n",
        "    print(\"-\", sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpeUINiN41_m",
        "outputId": "13ae5a51-f69c-4959-e352-b69a33a44d25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç LSA Summary:\n",
            "- Graph neural networks (GNNs) have emerged as a powerful framework for representation learning on graphs.\n",
            "- In this work, we investigate how architectural choices influence the performance of GNNs and propose new variants with improved expressiveness and efficiency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Final Example: Full pipeline demonstration\n",
        "text_to_summarize = \"\"\"\n",
        "Artificial Intelligence (AI) is transforming scientific research. With capabilities in automating data analysis, AI systems can process enormous datasets,\n",
        "generate hypotheses, and even assist in experimental design. Natural Language Processing (NLP) specifically aids in mining scientific literature by summarizing key findings,\n",
        "extracting concepts, and linking related works. Tools like TF-IDF, sentence embeddings, and deep learning summarizers are gaining popularity in research institutions.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìå Original Text:\")\n",
        "print(text_to_summarize)\n",
        "\n",
        "# Preprocess\n",
        "words = word_tokenize(text_to_summarize.lower())\n",
        "filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "filtered_text = ' '.join(filtered_words)\n",
        "\n",
        "# TF-IDF Summary\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sent_tokenize(text_to_summarize))\n",
        "scores = X.sum(axis=1).A1\n",
        "top_sentence_index = scores.argmax()\n",
        "print(\"\\nüìù TF-IDF Summary:\")\n",
        "print(sent_tokenize(text_to_summarize)[top_sentence_index])\n",
        "\n",
        "# LSA Summary\n",
        "parser = PlaintextParser.from_string(text_to_summarize, Tokenizer(\"english\"))\n",
        "lsa_summary = LsaSummarizer()(parser.document, 2)\n",
        "print(\"\\nüß† LSA Summary:\")\n",
        "for sentence in lsa_summary:\n",
        "    print(\"-\", sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjVHzTfM4_9n",
        "outputId": "c21b728f-b59c-4cab-aecf-e7897ddef5fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå Original Text:\n",
            "\n",
            "Artificial Intelligence (AI) is transforming scientific research. With capabilities in automating data analysis, AI systems can process enormous datasets,\n",
            "generate hypotheses, and even assist in experimental design. Natural Language Processing (NLP) specifically aids in mining scientific literature by summarizing key findings,\n",
            "extracting concepts, and linking related works. Tools like TF-IDF, sentence embeddings, and deep learning summarizers are gaining popularity in research institutions.\n",
            "\n",
            "\n",
            "üìù TF-IDF Summary:\n",
            "Natural Language Processing (NLP) specifically aids in mining scientific literature by summarizing key findings,\n",
            "extracting concepts, and linking related works.\n",
            "\n",
            "üß† LSA Summary:\n",
            "- Natural Language Processing (NLP) specifically aids in mining scientific literature by summarizing key findings, extracting concepts, and linking related works.\n",
            "- Tools like TF-IDF, sentence embeddings, and deep learning summarizers are gaining popularity in research institutions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2IxDtDRd5REY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}